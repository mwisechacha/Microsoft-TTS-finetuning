from transformers import SpeechT5ForTextToSpeech, SpeechT5HifiGan, AutoProcessor
import torch
import torchaudio
import streamlit as st

processor = AutoProcessor.from_pretrained("microsoft/speecht5_tts")
model = SpeechT5ForTextToSpeech.from_pretrained("MwiseChacha/SppechT5_finetuned_custom_dataset")
vocoder = SpeechT5HifiGan.from_pretrained("microsoft/speecht5_hifigan")


speaker_embeddings = torch.tensor([[-0.0773, -0.0390,  0.0314,  0.0191, -0.0516, -0.0443, -0.0666, -0.0525,
          0.0291,  0.0219, -0.0942, -0.0691,  0.0576,  0.0518,  0.0285,  0.0579,
          0.0213,  0.0260,  0.0083,  0.0045,  0.0364,  0.0132, -0.0122, -0.0499,
         -0.0557, -0.0079, -0.0297,  0.0412,  0.0495,  0.0123, -0.0031,  0.0647,
          0.0562,  0.0070,  0.0607, -0.0610,  0.0348,  0.0495, -0.0634, -0.0612,
          0.0571, -0.0248,  0.0345,  0.0388,  0.0160, -0.0970, -0.0187,  0.0130,
         -0.0751,  0.0357,  0.0009,  0.0324,  0.0539,  0.0212, -0.0999, -0.0088,
          0.0180, -0.0116,  0.0214,  0.0058,  0.0341, -0.0096, -0.0156,  0.0139,
          0.0059, -0.0080,  0.0339, -0.0540, -0.0534, -0.0796,  0.0089,  0.0116,
          0.0251,  0.0095,  0.0069,  0.0296,  0.0366,  0.0317, -0.0644, -0.0487,
         -0.0693, -0.0704, -0.0886, -0.0625, -0.0344, -0.0611, -0.0607,  0.0078,
          0.0145,  0.0648,  0.0272, -0.0905,  0.0041, -0.0776,  0.0207,  0.0179,
          0.0199,  0.0463, -0.0687, -0.0700,  0.0157, -0.0406, -0.0996,  0.0240,
          0.0445, -0.0283,  0.0579,  0.0237,  0.0065,  0.0312, -0.0579, -0.0201,
          0.0515, -0.0015,  0.0137,  0.0317, -0.0703,  0.0057, -0.0497,  0.0318,
          0.0455, -0.0652,  0.0299,  0.0445, -0.0657,  0.0364, -0.0613,  0.0245,
          0.0348,  0.0312,  0.0104,  0.0093,  0.0176,  0.0012,  0.0341, -0.0904,
         -0.0516,  0.0406, -0.0691, -0.0023, -0.0101,  0.0026, -0.0050,  0.0552,
         -0.0600,  0.0089, -0.0236, -0.0410,  0.0330, -0.1125,  0.0382, -0.0311,
         -0.0804,  0.0261, -0.0023,  0.0359,  0.0007, -0.0311, -0.0733,  0.0335,
          0.0386,  0.0194,  0.0392, -0.0319,  0.0049,  0.0108,  0.0295,  0.0347,
          0.0385,  0.0288,  0.0049, -0.0755,  0.0416, -0.0764, -0.0185,  0.0125,
         -0.0554,  0.0085,  0.0425, -0.0898,  0.0325, -0.0597, -0.0080,  0.0214,
         -0.0593, -0.0093,  0.0202,  0.0431, -0.0388, -0.0787, -0.0085,  0.0441,
         -0.0709,  0.0096,  0.0398,  0.0004,  0.0695,  0.0376,  0.0488, -0.0074,
          0.0456,  0.0176, -0.0618,  0.0065,  0.0016,  0.0083,  0.0212, -0.0119,
          0.0360,  0.0009,  0.0049, -0.0782, -0.0390,  0.0501, -0.0598,  0.0193,
          0.0336, -0.0915,  0.0485,  0.0152, -0.0631,  0.0216, -0.0765, -0.0083,
          0.0541,  0.0320,  0.0471,  0.0762,  0.0385,  0.0414, -0.0042,  0.0574,
          0.0275, -0.0442,  0.0193, -0.0708,  0.0415,  0.0132, -0.0020,  0.0638,
         -0.0639,  0.0198, -0.0988,  0.0279, -0.0570,  0.0050,  0.0524,  0.0327,
          0.0623,  0.0382,  0.0542, -0.0099,  0.0080, -0.0400,  0.0152,  0.0390,
          0.0382,  0.0563, -0.0629,  0.0579,  0.0069, -0.0598,  0.0249,  0.0226,
          0.0012,  0.0210,  0.0327,  0.0314, -0.0018, -0.0480,  0.0638,  0.0164,
         -0.0389, -0.0180, -0.0550,  0.0304,  0.0167,  0.0016, -0.0857, -0.0552,
         -0.0113,  0.0412,  0.0273, -0.0764, -0.0569,  0.0569,  0.0142,  0.0373,
         -0.0932, -0.0011,  0.0063,  0.0277, -0.0390, -0.0004, -0.0405,  0.0331,
          0.0131, -0.0173,  0.0143,  0.0224,  0.0613,  0.0379,  0.0204, -0.0646,
          0.0211,  0.0370,  0.0259,  0.0517,  0.0179,  0.0474,  0.0212,  0.0180,
         -0.0042,  0.0370, -0.0784, -0.0867, -0.0263,  0.0379, -0.0641,  0.0710,
         -0.0445,  0.0391, -0.0519,  0.0152,  0.0323, -0.0808,  0.0333,  0.0427,
         -0.0466, -0.0779, -0.0684,  0.0144,  0.0221,  0.0330, -0.0596, -0.0028,
          0.0129, -0.0460, -0.0098, -0.0605,  0.0096, -0.0510,  0.0177,  0.0038,
         -0.0884,  0.0272,  0.0525,  0.0308, -0.0658, -0.0562, -0.0414,  0.0024,
         -0.0749,  0.1055,  0.0284, -0.0392, -0.0065,  0.0431, -0.0514, -0.0190,
         -0.1037,  0.0099,  0.0182,  0.0603,  0.0287,  0.0061, -0.0416,  0.0110,
          0.0106,  0.0444,  0.0123,  0.0465, -0.0564,  0.0228, -0.0132, -0.0023,
          0.0191,  0.0035,  0.0530,  0.0292, -0.0726, -0.1207,  0.0261,  0.0168,
          0.0488, -0.0492,  0.0391, -0.0488,  0.0376,  0.0357,  0.0448,  0.0172,
         -0.0677,  0.0626,  0.0019,  0.0022,  0.0477, -0.0639,  0.0033,  0.0349,
         -0.0119, -0.0341,  0.0503,  0.0235,  0.0218,  0.0087,  0.0155, -0.0642,
         -0.0536, -0.0842, -0.0764,  0.0146,  0.0441, -0.0138,  0.0447, -0.0391,
         -0.0062, -0.0739, -0.1208, -0.0402, -0.0554,  0.0211,  0.0431, -0.0361,
         -0.0605,  0.0064,  0.0181,  0.0220,  0.0318, -0.0459, -0.0365, -0.0188,
         -0.0301,  0.0353, -0.0154,  0.0042,  0.0446,  0.0502, -0.0533, -0.0503,
          0.0219,  0.0586,  0.0227,  0.0033, -0.0360,  0.0165,  0.0307,  0.0106,
          0.0066, -0.0137,  0.0486,  0.0224, -0.0052,  0.0110,  0.0144, -0.0169,
          0.0300, -0.0764, -0.0703,  0.0159, -0.0123,  0.0121,  0.0526,  0.0332,
         -0.0899,  0.0271,  0.0248, -0.0567,  0.0360,  0.0254, -0.0028,  0.0362,
          0.0161,  0.0053, -0.0464, -0.0830,  0.0090, -0.0057,  0.0473,  0.0316,
         -0.0619, -0.0601,  0.0515,  0.0578,  0.0555,  0.0375, -0.0454, -0.0127,
         -0.0218, -0.0124, -0.0454,  0.0428, -0.0344,  0.0405,  0.0157, -0.0017,
         -0.0568, -0.0470, -0.0832, -0.0339,  0.0080,  0.0277, -0.0576,  0.0199,
          0.0474, -0.0151, -0.0657,  0.0352,  0.0355,  0.0260,  0.0294, -0.0688]])

def text_to_speech(text, speaker_embeddings):
    inputs = processor(text=text, return_tensors="pt")
    with torch.no_grad():
        speech = model.generate_speech(inputs['input_ids'], 
            speaker_embeddings=speaker_embeddings)
    with torch.no_grad():
        speech = vocoder(speech).squeeze()

    return speech



def main():
    st.markdown("""
    <h1 style="text-align: center;background: linear-gradient(to right, yellow, green, lightblue); -webkit-background-clip: text; color: transparent; font-size: 2.5em;"> AICE Africa Tailored Text-to-Speech Solution </h1>
    """, unsafe_allow_html=True)

    st.markdown("""
    <style>
    .stTextInput>div>div>div>input {
        padding: 10px;
        border-radius: 10px;
        border: 2px solid #ccc;
    }

    .stButton>button {
        background: linear-gradient(to right, yellow, green);
        color: white;
        padding: 10px 20px;
        border: none;
        border-radius: 10px;
        cursor: pointer;
        font-size: 1em;
    }

    .stButton> button:hover {
        background: linear-gradient(to right, green, yellow);
    }

    .audio-container {
        background: linear-gradient(to right, yellow, green);
        padding: 10px;
        border-radius: 10px;
        text-align: center;
        margin-top: 10px;
    }

    .audio-container audio {
        border-radius: 10px;
        width: 100%;
    }

    .voice-indicator {
        font-size: 1.2em;
        color: #333;
        text-align: center;
        margin-top: 10px;
    }
    </style>
""", unsafe_allow_html=True)

    user_input = st.text_input("Enter your text")

    audio = None

    if st.button("Generate Audio"):
        audio = text_to_speech(user_input, speaker_embeddings)

    if audio is not None:
        if audio.dim() == 1:
            audio = audio.unsqueeze(0)

        audio_path = "output.wav"
        torchaudio.save(audio_path, audio, 16000)

        st.audio(audio_path)
        
        st.markdown('<div class="voice-indicator">Generated with Irene Kiwia\'s Voice</div>', unsafe_allow_html=True)

if __name__ == "__main__":
    main()



